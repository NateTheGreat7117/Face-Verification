{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5626d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import albumentations as alb\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import skimage\n",
    "import math\n",
    "import glob\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9e7afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoid out of memory errors\n",
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06fa20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20d331a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "image_paths1 = os.listdir(\"images/images/\")\n",
    "anchor_paths = os.listdir(\"images/anchor/\")\n",
    "repeated_faces = []\n",
    "\n",
    "for path in image_paths1:\n",
    "    if len(os.listdir(f\"images/images/{path}/\")) > 1:\n",
    "        repeated_faces.append(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b019967d",
   "metadata": {},
   "outputs": [],
   "source": [
    "HEIGHT = 120\n",
    "WIDTH = 120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed6586c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_image(file):\n",
    "    byte_img = tf.io.read_file(file)\n",
    "    img = tf.io.decode_jpeg(byte_img)\n",
    "    img = tf.image.resize(img, (HEIGHT, WIDTH))\n",
    "    return img / 255.0\n",
    "\n",
    "x = []\n",
    "anchors = []\n",
    "\n",
    "for person in repeated_faces:\n",
    "    faces = os.listdir(f\"images/images/{person}/\")\n",
    "    temp = []\n",
    "    for face in faces:\n",
    "        temp.append(get_image(f\"images/images/{person}/{face}\"))\n",
    "    x.append(temp)\n",
    "    \n",
    "for anchor in anchor_paths:\n",
    "    anchors.append(get_image(f\"images/anchor/{anchor}\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4f280b",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f1031a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(anchors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60aa9006",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test = x[:1400], x[1400:]\n",
    "anchors_train, anchors_test = anchors[:1500], anchors[1500:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8daca09",
   "metadata": {},
   "outputs": [],
   "source": [
    "def augmentor(img):\n",
    "    img = tf.image.stateless_random_brightness(img, max_delta=0.02, seed=(1,2))\n",
    "    img = tf.image.stateless_random_contrast(img, lower=0.6, upper=1, seed=(1,3))\n",
    "    img = tf.image.stateless_random_flip_left_right(img, seed=(np.random.randint(100),np.random.randint(100)))\n",
    "    img = tf.image.stateless_random_jpeg_quality(img, min_jpeg_quality=90, max_jpeg_quality=100, seed=(np.random.randint(100),np.random.randint(100)))\n",
    "    img = tf.image.stateless_random_saturation(img, lower=0.9,upper=1, seed=(np.random.randint(100),np.random.randint(100)))\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72bf7ce8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch1(batch_size, validation=False):\n",
    "    x = x_train\n",
    "    if validation:\n",
    "        x = x_test\n",
    "    batch_x = []\n",
    "    \n",
    "    batch_y = np.zeros(batch_size)\n",
    "    batch_y[int(batch_size/2):] = 1\n",
    "    np.random.shuffle(batch_y)\n",
    "    \n",
    "    class_list = np.random.randint(0, len(x), batch_size)\n",
    "    batch_x.append(np.zeros((batch_size, HEIGHT, WIDTH, 3)))\n",
    "    batch_x.append(np.zeros((batch_size, HEIGHT, WIDTH, 3)))\n",
    "    \n",
    "    for i in range(0, batch_size):\n",
    "        person = x[np.random.choice(len(x))]\n",
    "        batch_x[0][i] = person[np.random.choice(len(person))]\n",
    "        batch_x[0][i] = augmentor(batch_x[0][i])\n",
    "        \n",
    "        # Same\n",
    "        if batch_y[i] == 0:\n",
    "            batch_x[1][i] = person[np.random.choice(len(person))]\n",
    "            \n",
    "        # Different\n",
    "        if batch_y[i] == 1:\n",
    "            new_person = x[np.random.choice(len(x))]\n",
    "            while np.array_equal(new_person, person):\n",
    "                new_person = x[np.random.choice(len(x))]\n",
    "            batch_x[1][i] = new_person[np.random.choice(len(new_person))]\n",
    "            batch_x[1][i] = augmentor(batch_x[1][i])\n",
    "            \n",
    "    return (batch_x, batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a40802",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_batch2(batch_size, validation=False):\n",
    "    anchor = anchors_train\n",
    "    x = x_train\n",
    "    if validation:\n",
    "        anchor = anchors_test\n",
    "        x = x_test\n",
    "    batch_x = []\n",
    "    \n",
    "    batch_y = np.zeros(batch_size)\n",
    "    batch_y[int(batch_size/2):] = 1\n",
    "    np.random.shuffle(batch_y)\n",
    "    \n",
    "    class_list = np.random.randint(0, len(x), batch_size)\n",
    "    batch_x.append(np.zeros((batch_size, HEIGHT, WIDTH, 3)))\n",
    "    batch_x.append(np.zeros((batch_size, HEIGHT, WIDTH, 3)))\n",
    "    \n",
    "    for i in range(0, batch_size):\n",
    "        batch_x[0][i] = anchor[np.random.choice(len(anchor))]\n",
    "        batch_x[0][i] = augmentor(batch_x[0][i])\n",
    "        \n",
    "        # Same\n",
    "        if batch_y[i] == 0:\n",
    "            batch_x[1][i] = anchor[np.random.choice(len(anchor))]\n",
    "            \n",
    "        # Different\n",
    "        if batch_y[i] == 1:\n",
    "            person = x[np.random.choice(len(x))]\n",
    "            batch_x[1][i] = person[np.random.choice(len(person))]\n",
    "            batch_x[1][i] = augmentor(batch_x[1][i])\n",
    "            \n",
    "    return (batch_x, batch_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f97adfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = get_batch2(16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10747c0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d024b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axes = plt.subplots(1, 2, figsize=(15,15))\n",
    "axes[0].imshow(batch[0][0][3])\n",
    "axes[1].imshow(batch[0][1][3])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0868863f",
   "metadata": {},
   "source": [
    "# Create Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9461fb24",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_pretrained_model():\n",
    "    input_1 = tf.keras.layers.Input(shape=(HEIGHT, WIDTH, 3))\n",
    "    input_2 = tf.keras.layers.Input(shape=(HEIGHT, WIDTH, 3))\n",
    "    \n",
    "    base_model = tf.keras.applications.VGG19(include_top=False, weights='imagenet')\n",
    "    \n",
    "    x1 = base_model(input_1)\n",
    "    x1 = tf.keras.layers.GlobalMaxPooling2D()(x1)\n",
    "    x1 = tf.keras.layers.Dense(256, activation=\"relu\")(x1)\n",
    "    x1 = tf.keras.layers.Dropout(0.5)(x1)\n",
    "    x1 = tf.keras.layers.Dense(1024, activation=\"relu\")(x1)\n",
    "    \n",
    "    x2 = base_model(input_2)\n",
    "    x2 = tf.keras.layers.GlobalMaxPooling2D()(x2)\n",
    "    x2 = tf.keras.layers.Dense(256, activation=\"relu\")(x2)\n",
    "    x2 = tf.keras.layers.Dropout(0.5)(x2)\n",
    "    x2 = tf.keras.layers.Dense(1024, activation=\"relu\")(x2)\n",
    "\n",
    "    diff = tf.keras.layers.Lambda(lambda x: tf.abs(x[0] - x[1]))([x1, x2])\n",
    "    output = tf.keras.layers.Dense(1, activation='sigmoid')(diff)\n",
    "    \n",
    "    siamese_model = tf.keras.Model(inputs=[input_1, input_2], outputs=output)\n",
    "    return siamese_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be47ddf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#siamese_model = create_siamese_model()\n",
    "siamese_model = create_pretrained_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d07e9a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n",
    "                      loss=\"binary_crossentropy\",\n",
    "                      metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7297dec9",
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66028dbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss():\n",
    "    # Plotting\n",
    "    losses = [x for x in loss_list]\n",
    "    val_losses = [x for x in val_loss_list]\n",
    "    accuracies = [x for x in accuracy_list]\n",
    "    val_accuracies = [x for x in val_accuracy_list]\n",
    "\n",
    "    f, axs = plt.subplots(2, 2, figsize=(15,5))\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    axs[0][0].plot(losses, label=\"loss\")\n",
    "    axs[1][0].plot(accuracies, label=\"accuracy\", color=\"orange\")\n",
    "    axs[0][1].plot(val_losses, label=\"val loss\")\n",
    "    axs[1][1].plot(val_accuracies, label=\"val accuracy\", color=\"orange\")\n",
    "    plt.ylim([0, 1])\n",
    "\n",
    "    axs[0][0].legend()\n",
    "    axs[0][0].grid()\n",
    "    axs[0][1].legend()\n",
    "    axs[0][1].grid()\n",
    "    axs[1][0].legend()\n",
    "    axs[1][0].grid()\n",
    "    axs[1][1].legend()\n",
    "    axs[1][1].grid()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    print(\"Loss: \", loss_list[-1], \"        Validation loss: \", val_loss_list[-1])\n",
    "    print(\"Accuracy: \", accuracy_list[-1], \" \"*(len(str(loss_list[-1])) - len(str(accuracy_list[-1]))), \n",
    "                                               \"   Validation accuracy: \", val_accuracy_list[-1])\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc5ab04",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "EPOCHS = 5000\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "loss_list = []\n",
    "val_loss_list = []\n",
    "accuracy_list = []\n",
    "val_accuracy_list = []\n",
    "\n",
    "for epoch in range(1, EPOCHS+1):\n",
    "#     if np.random.randint(4):\n",
    "#         batch_x, batch_y = get_batch1(BATCH_SIZE)\n",
    "#     else:\n",
    "    batch_x, batch_y = get_batch1(BATCH_SIZE)\n",
    "        \n",
    "    loss, accuracy = siamese_model.train_on_batch(batch_x, batch_y)\n",
    "    loss_list.append(loss)\n",
    "    accuracy_list.append(accuracy)\n",
    "    print(\"Epoch: \", epoch, \", Loss: \", loss, \", Acc:\", accuracy)\n",
    "    batch_x_val, batch_y_val = get_batch1(BATCH_SIZE)\n",
    "    val_loss, val_accuracy = siamese_model.evaluate(batch_x_val, batch_y_val, verbose=0)\n",
    "    val_loss_list.append(val_loss)\n",
    "    val_accuracy_list.append(val_accuracy)\n",
    "    if epoch % 10 == 0:\n",
    "        plot_loss()\n",
    "\n",
    "#os.system(\"rundll32.exe powrprof.dll,SetSuspendState 0,1,0\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db9c643b",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([loss_list[i] for i in range(0, len(loss_list), 50)], label='loss')\n",
    "plt.plot([val_loss_list[i] for i in range(0, len(val_loss_list), 50)], label='val_loss')\n",
    "plt.ylim([0, 1])\n",
    "plt.xlabel('Epoch #')\n",
    "plt.ylabel('CE/token')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df1e881",
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_model.predict([np.expand_dims(get_image(\"images/Nathan1.jpeg\"), axis=0),\n",
    "                       np.expand_dims(get_image(\"images/Tito.jpg\"), axis=0)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3798cb95",
   "metadata": {},
   "source": [
    "# Save to TFLite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e61d276",
   "metadata": {},
   "outputs": [],
   "source": [
    "siamese_model.save(\"face_verification\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fbdb200",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.models.load_model(\"siamese_model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd03bf13",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.predict([np.expand_dims(get_image(\"images/Nathan1.jpeg\"), axis=0),\n",
    "               np.expand_dims(get_image(\"images/Tito.jpeg\"), axis=0)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d185f1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "converter = tf.lite.TFLiteConverter.from_saved_model(\"siamese_model\")\n",
    "tflite_model = converter.convert()\n",
    "\n",
    "with open(\"model.tflite\", \"wb\") as f:\n",
    "    f.write(tflite_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8b480f",
   "metadata": {},
   "outputs": [],
   "source": [
    "interpreter = tf.lite.Interpreter(\"model.tflite\")\n",
    "my_signature = interpreter.get_signature_runner()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69e9ce26",
   "metadata": {},
   "outputs": [],
   "source": [
    "my_signature()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afa4719b",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = my_signature(input_15=tf.cast(np.expand_dims(get_image(BASE_PATH + \"/images/Jamie.jpeg\"), axis=0), tf.float32),\n",
    "                      input_16=tf.cast(np.expand_dims(get_image(BASE_PATH + \"/images/Nathan2.jpeg\"), axis=0), tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1288397",
   "metadata": {},
   "outputs": [],
   "source": [
    "output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
